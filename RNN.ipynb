{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDfqbp2VEOG5",
        "outputId": "81f2405f-2937-45fe-c75a-d86ef085affb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import utils_data as utils\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.functional as F\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AFaNzmXEOG6"
      },
      "source": [
        "### Importation du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5WcGG-cWEOG7"
      },
      "outputs": [],
      "source": [
        "data_train, data_val = utils.get_data()\n",
        "label_train, label_val = utils.get_labels()\n",
        "data_test = utils.get_test()\n",
        "\n",
        "merged_train = utils.merge_data_labels(data_train, label_train)\n",
        "merged_val = utils.merge_data_labels(data_val, label_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GZJfwPWEOG7"
      },
      "source": [
        "Note importante : toute la suite est inspiré de : https://coderzcolumn.com/tutorials/artificial-intelligence/pytorch-rnn-for-text-classification-tasks, ainsi que du cours IFT 6135-A2022."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty6n7mr-EOG7"
      },
      "source": [
        "### Création de tokens à partir des phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H9b0_HSEOG7",
        "outputId": "917bd982-d02b-4621-d1a2-2d6d98cfa9c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "579310"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        for text in dataset:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data_train, data_val, data_test]), min_freq=1, specials=[\"<UNK>\"])\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "857_mKwVEOG8"
      },
      "source": [
        "### Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BKZvzdKSEOG8"
      },
      "outputs": [],
      "source": [
        "data_train, data_val = to_map_style_dataset(merged_train), to_map_style_dataset(merged_val)\n",
        "data_test = to_map_style_dataset(data_test)\n",
        "target_classes = [\"negative\", \"neutral\", \"positive\"]\n",
        "max_words = 100\n",
        "\n",
        "def vectorize_batch(batch):\n",
        "    X, Y = list(zip(*batch))\n",
        "    X = [vocab(tokenizer(text)) for text in X]\n",
        "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.int32), torch.tensor(Y, dtype = torch.long)\n",
        "\n",
        "def vectorize_test_batch(batch):\n",
        "    X = list(batch)\n",
        "    X = [vocab(tokenizer(text)) for text in X]\n",
        "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.int32)\n",
        "\n",
        "train_loader = DataLoader(data_train, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n",
        "val_loader = DataLoader(data_val, batch_size=1024, collate_fn=vectorize_batch)\n",
        "test_loader = DataLoader(data_test, batch_size=1024, collate_fn=vectorize_test_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HDOXv9TEOG8"
      },
      "source": [
        "### Définition du RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOy7TJHbEOG9",
        "outputId": "612aa725-3011-45c6-f267-5c90e279f766"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNClassifier(\n",
              "  (embedding_layer): Embedding(579310, 50)\n",
              "  (rnn): RNN(50, 25, batch_first=True)\n",
              "  (linear): Linear(in_features=25, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "embed_len = 100\n",
        "hidden_dim = 50\n",
        "n_layers = 1\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len, device = device)\n",
        "        self.rnn = nn.RNN(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, len(target_classes), device = device)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch).to(device)\n",
        "        output, hidden = self.rnn(embeddings, torch.randn(n_layers, len(X_batch), hidden_dim, device = device))\n",
        "        return self.linear(output[:,-1])\n",
        "\n",
        "rnn_classifier = RNNClassifier().to(device)\n",
        "rnn_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU7o46SDEOG9",
        "outputId": "dd3993f4-714a-4156-a0a2-952a956cb07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer : Embedding(579310, 50)\n",
            "Parameters : \n",
            "torch.Size([579310, 50])\n",
            "\n",
            "Layer : RNN(50, 25, batch_first=True)\n",
            "Parameters : \n",
            "torch.Size([25, 50])\n",
            "torch.Size([25, 25])\n",
            "torch.Size([25])\n",
            "torch.Size([25])\n",
            "\n",
            "Layer : Linear(in_features=25, out_features=3, bias=True)\n",
            "Parameters : \n",
            "torch.Size([3, 25])\n",
            "torch.Size([3])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for layer in rnn_classifier.children():\n",
        "    print(\"Layer : {}\".format(layer))\n",
        "    print(\"Parameters : \")\n",
        "    for param in layer.parameters():\n",
        "        print(param.shape)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC8-YNWcEOG9"
      },
      "source": [
        "### Entraînement du RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EnpWFX1qEOG9"
      },
      "outputs": [],
      "source": [
        "def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n",
        "    with torch.no_grad():\n",
        "        Y_shuffled, Y_preds, losses = [],[],[]\n",
        "        for X, Y in val_loader:\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            preds = model(X)\n",
        "            loss = loss_fn(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            Y_shuffled.append(Y)\n",
        "            Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "        Y_shuffled = torch.cat(Y_shuffled)\n",
        "        Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().cpu().numpy(), Y_preds.detach().cpu().numpy())))\n",
        "\n",
        "\n",
        "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            Y_preds = model(X)\n",
        "\n",
        "            loss = loss_fn(Y_preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        CalcValLossAndAccuracy(model, loss_fn, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KflHzO4sEOG-"
      },
      "outputs": [],
      "source": [
        "epochs = 15\n",
        "learning_rate = 1e-3\n",
        "\n",
        "rnn_classifier = RNNClassifier().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(rnn_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "#TrainModel(rnn_classifier, loss_fn, optimizer, train_loader, val_loader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM9hYKfHEOG-"
      },
      "source": [
        "### Prédictions sur l'ensemble de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "swTDpMYdEOG-",
        "outputId": "95e764e0-6463-4ecf-de6e-7d369ff48b60"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-92e13ebe8db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mY_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMakePredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-92e13ebe8db7>\u001b[0m in \u001b[0;36mMakePredictions\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mY_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-5c231e97b7c7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    471\u001b[0m                 result = _VF.rnn_tanh(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m    472\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                                       self.batch_first)\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 result = _VF.rnn_relu(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 68.00 MiB (GPU 0; 14.76 GiB total capacity; 13.32 GiB already allocated; 9.75 MiB free; 13.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "def MakePredictions(model, loader):\n",
        "    Y_preds = []\n",
        "    for X in loader:\n",
        "        X = X.to(device)\n",
        "        preds = model(X)\n",
        "        Y_preds.append(preds)\n",
        "    gc.collect()\n",
        "    Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "    return F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().cpu().numpy()\n",
        "\n",
        "Y_preds = MakePredictions(rnn_classifier, test_loader)\n",
        "print(Y_preds[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLRzU1rvEOG-"
      },
      "source": [
        "### Enregistrement des résultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "aGTsXRzuEOG_",
        "outputId": "7fb2959c-5e47-4329-c3b1-01e83fddfb95"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b79d909739ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Y_preds' is not defined"
          ]
        }
      ],
      "source": [
        "utils.save_results(Y_preds, \"RNN\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c5fb5e78068286ad4ec2111baba118e0d35af9e9b40524b1c6e140f245c1a137"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}